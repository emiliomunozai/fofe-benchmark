{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cd425b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "# Set project root\n",
    "repo_name = \"\\\\thesis\"\n",
    "os.chdir(os.getcwd().split(repo_name)[0] + repo_name)\n",
    "print(f'Changed working directory to: {os.getcwd()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281f8aa0",
   "metadata": {},
   "source": [
    "#### 1. Corpus Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf8cac1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "588775"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load data\n",
    "examples = pickle.load(open(\"data/examples.pkl\", \"rb\"))\n",
    "vocab = pickle.load(open(\"data/vocab.pkl\", \"rb\"))\n",
    "\n",
    "len(examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde47a97",
   "metadata": {},
   "source": [
    "#### 2. Run Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f189e872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket (32, 63): 274333 examples\n",
      "Bucket (64, 127): 232721 examples\n",
      "Bucket (128, 255): 77093 examples\n",
      "Bucket (256, 511): 4593 examples\n",
      "Bucket (512, 1023): 35 examples\n"
     ]
    }
   ],
   "source": [
    "from src.model_training import train_one_bucket, TrainConfig\n",
    "from src.dataloaders import bucket_examples_by_distance\n",
    "\n",
    "\n",
    "# Define distance buckets (inclusive ranges)\n",
    "distance_buckets = [\n",
    "    (32, 63),\n",
    "    (64, 127),\n",
    "    (128, 255),\n",
    "    (256, 511),\n",
    "    (512, 1023)\n",
    "]\n",
    "\n",
    "# Bucket all examples\n",
    "bucketed = bucket_examples_by_distance(examples, distance_buckets)\n",
    "\n",
    "# Print size by bucket dict keys\n",
    "for bucket in distance_buckets:\n",
    "    print(f\"Bucket {bucket}: {len(bucketed[bucket])} examples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5eca197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training on distance buckets...\n",
      "\n",
      "Training on bucket 0\n",
      "Bucket range: 32–63 tokens\n",
      "====================================================================================================\n",
      "Training on bucket 0 FOFENet\n",
      "====================================================================================================\n",
      "Number of parameters: 42297346\n",
      "Class balance: neg=64.87%, pos=35.13%\n",
      "Training bucket of size 129991 (train 103992, val 25999)\n",
      "Epoch 1/15 | Train Loss: 0.6821 Train Acc: 56.37% | Val Loss: 0.6733 Val Acc: 59.26% | LR: 0.000700\n",
      "Epoch 2/15 | Train Loss: 0.6650 Train Acc: 60.05% | Val Loss: 0.6707 Val Acc: 62.48% | LR: 0.000700\n",
      "Epoch 3/15 | Train Loss: 0.6541 Train Acc: 62.17% | Val Loss: 0.6668 Val Acc: 62.06% | LR: 0.000700\n",
      "Epoch 4/15 | Train Loss: 0.6423 Train Acc: 63.96% | Val Loss: 0.6679 Val Acc: 57.63% | LR: 0.000700\n",
      "Epoch 5/15 | Train Loss: 0.6275 Train Acc: 66.01% | Val Loss: 0.6727 Val Acc: 64.07% | LR: 0.000700\n",
      "Epoch 6/15 | Train Loss: 0.6094 Train Acc: 68.38% | Val Loss: 0.6687 Val Acc: 61.76% | LR: 0.000350\n",
      "Epoch 7/15 | Train Loss: 0.5715 Train Acc: 72.73% | Val Loss: 0.6906 Val Acc: 63.50% | LR: 0.000350\n",
      "Epoch 8/15 | Train Loss: 0.5484 Train Acc: 75.27% | Val Loss: 0.7008 Val Acc: 62.56% | LR: 0.000350\n",
      "Epoch 9/15 | Train Loss: 0.5253 Train Acc: 77.36% | Val Loss: 0.7128 Val Acc: 63.77% | LR: 0.000175\n",
      "Epoch 10/15 | Train Loss: 0.4882 Train Acc: 80.83% | Val Loss: 0.7362 Val Acc: 63.04% | LR: 0.000175\n",
      "Epoch 11/15 | Train Loss: 0.4702 Train Acc: 82.42% | Val Loss: 0.7528 Val Acc: 62.67% | LR: 0.000175\n",
      "Epoch 12/15 | Train Loss: 0.4565 Train Acc: 83.62% | Val Loss: 0.7649 Val Acc: 63.15% | LR: 0.000087\n",
      "Epoch 13/15 | Train Loss: 0.4341 Train Acc: 85.50% | Val Loss: 0.7793 Val Acc: 63.15% | LR: 0.000087\n",
      "Epoch 14/15 | Train Loss: 0.4242 Train Acc: 86.33% | Val Loss: 0.7910 Val Acc: 63.85% | LR: 0.000087\n",
      "Epoch 15/15 | Train Loss: 0.4155 Train Acc: 87.11% | Val Loss: 0.8010 Val Acc: 64.71% | LR: 0.000044\n",
      "Training time: 108.01 seconds\n",
      "====================================================================================================\n",
      "Training on bucket 0 BiLSTM\n",
      "====================================================================================================\n",
      "Number of parameters: 43284226\n",
      "Class balance: neg=64.87%, pos=35.13%\n",
      "Training bucket of size 129991 (train 103992, val 25999)\n",
      "Epoch 1/15 | Train Loss: 0.6540 Train Acc: 61.53% | Val Loss: 0.6357 Val Acc: 65.15% | LR: 0.000700\n",
      "Epoch 2/15 | Train Loss: 0.6146 Train Acc: 67.06% | Val Loss: 0.6244 Val Acc: 65.54% | LR: 0.000700\n",
      "Epoch 3/15 | Train Loss: 0.5894 Train Acc: 70.25% | Val Loss: 0.6195 Val Acc: 68.09% | LR: 0.000700\n",
      "Epoch 4/15 | Train Loss: 0.5675 Train Acc: 72.71% | Val Loss: 0.6251 Val Acc: 65.87% | LR: 0.000700\n",
      "Epoch 5/15 | Train Loss: 0.5490 Train Acc: 74.55% | Val Loss: 0.6318 Val Acc: 66.13% | LR: 0.000700\n",
      "Epoch 6/15 | Train Loss: 0.5316 Train Acc: 76.26% | Val Loss: 0.6342 Val Acc: 68.17% | LR: 0.000350\n",
      "Epoch 7/15 | Train Loss: 0.4880 Train Acc: 80.38% | Val Loss: 0.6449 Val Acc: 69.76% | LR: 0.000350\n",
      "Epoch 8/15 | Train Loss: 0.4682 Train Acc: 82.17% | Val Loss: 0.6708 Val Acc: 69.17% | LR: 0.000350\n",
      "Epoch 9/15 | Train Loss: 0.4503 Train Acc: 83.73% | Val Loss: 0.6772 Val Acc: 69.12% | LR: 0.000175\n",
      "Epoch 10/15 | Train Loss: 0.4134 Train Acc: 86.92% | Val Loss: 0.7079 Val Acc: 69.18% | LR: 0.000175\n",
      "Epoch 11/15 | Train Loss: 0.3981 Train Acc: 88.18% | Val Loss: 0.7190 Val Acc: 69.00% | LR: 0.000175\n",
      "Epoch 12/15 | Train Loss: 0.3851 Train Acc: 89.30% | Val Loss: 0.7363 Val Acc: 69.01% | LR: 0.000087\n",
      "Epoch 13/15 | Train Loss: 0.3625 Train Acc: 91.19% | Val Loss: 0.7550 Val Acc: 68.23% | LR: 0.000087\n",
      "Epoch 14/15 | Train Loss: 0.3532 Train Acc: 91.93% | Val Loss: 0.7638 Val Acc: 68.35% | LR: 0.000087\n",
      "Epoch 15/15 | Train Loss: 0.3465 Train Acc: 92.48% | Val Loss: 0.7773 Val Acc: 69.08% | LR: 0.000044\n",
      "Training time: 67.02 seconds\n",
      "Training on bucket 1\n",
      "Bucket range: 64–127 tokens\n",
      "====================================================================================================\n",
      "Training on bucket 1 FOFENet\n",
      "====================================================================================================\n",
      "Number of parameters: 42297346\n",
      "Class balance: neg=64.94%, pos=35.06%\n",
      "Training bucket of size 108120 (train 86496, val 21624)\n",
      "Epoch 1/15 | Train Loss: 0.6877 Train Acc: 54.95% | Val Loss: 0.6808 Val Acc: 58.55% | LR: 0.000700\n",
      "Epoch 2/15 | Train Loss: 0.6712 Train Acc: 58.78% | Val Loss: 0.6777 Val Acc: 56.61% | LR: 0.000700\n",
      "Epoch 3/15 | Train Loss: 0.6611 Train Acc: 60.74% | Val Loss: 0.6768 Val Acc: 60.65% | LR: 0.000700\n",
      "Epoch 4/15 | Train Loss: 0.6488 Train Acc: 62.86% | Val Loss: 0.6762 Val Acc: 58.67% | LR: 0.000700\n",
      "Epoch 5/15 | Train Loss: 0.6327 Train Acc: 65.23% | Val Loss: 0.6844 Val Acc: 57.90% | LR: 0.000700\n",
      "Epoch 6/15 | Train Loss: 0.6122 Train Acc: 67.97% | Val Loss: 0.6868 Val Acc: 61.18% | LR: 0.000700\n",
      "Epoch 7/15 | Train Loss: 0.5888 Train Acc: 70.79% | Val Loss: 0.6975 Val Acc: 62.10% | LR: 0.000350\n",
      "Epoch 8/15 | Train Loss: 0.5422 Train Acc: 75.79% | Val Loss: 0.7285 Val Acc: 61.87% | LR: 0.000350\n",
      "Epoch 9/15 | Train Loss: 0.5128 Train Acc: 78.52% | Val Loss: 0.7397 Val Acc: 60.64% | LR: 0.000350\n",
      "Epoch 10/15 | Train Loss: 0.4887 Train Acc: 80.71% | Val Loss: 0.7622 Val Acc: 60.89% | LR: 0.000175\n",
      "Epoch 11/15 | Train Loss: 0.4510 Train Acc: 84.06% | Val Loss: 0.7933 Val Acc: 61.91% | LR: 0.000175\n",
      "Epoch 12/15 | Train Loss: 0.4336 Train Acc: 85.57% | Val Loss: 0.8068 Val Acc: 61.67% | LR: 0.000175\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 37\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m100\u001b[39m)\n\u001b[32m     36\u001b[39m start_time = time.time()\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m val_acc_fofe = \u001b[43mtrain_one_bucket\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbucket\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m end_time = time.time()\n\u001b[32m     39\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTraining time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_time\u001b[38;5;250m \u001b[39m-\u001b[38;5;250m \u001b[39mstart_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m seconds\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\EMILIO\\Desktop\\0. Cursos\\6. LLMs & Applications\\fofe-benchmark\\src\\model_training.py:143\u001b[39m, in \u001b[36mtrain_one_bucket\u001b[39m\u001b[34m(bucket, bucket_max_len, vocab, cfg)\u001b[39m\n\u001b[32m    140\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTraining bucket of size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(bucket)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (train \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(train_ex)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, val \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(val_ex)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, cfg.epochs + \u001b[32m1\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m     train_loss, train_acc = \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    144\u001b[39m     val_loss,   val_acc   = evaluate(model, val_loader, criterion, cfg.device)\n\u001b[32m    145\u001b[39m     scheduler.step(val_loss)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\EMILIO\\Desktop\\0. Cursos\\6. LLMs & Applications\\fofe-benchmark\\src\\model_training.py:54\u001b[39m, in \u001b[36mtrain_one_epoch\u001b[39m\u001b[34m(model, loader, optimizer, criterion, device)\u001b[39m\n\u001b[32m     51\u001b[39m     optimizer.step()\n\u001b[32m     53\u001b[39m     preds = logits.argmax(dim=-\u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     total_loss += \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m     total_acc += compute_accuracy(preds, y)\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m total_loss / \u001b[38;5;28mlen\u001b[39m(loader), total_acc / \u001b[38;5;28mlen\u001b[39m(loader)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "import time\n",
    "from src.model_training import set_seed\n",
    "from src.model_training import train_one_bucket, train_one_bucket_lstm\n",
    "\n",
    "print(\"Starting training on distance buckets...\\n\")\n",
    "\n",
    "vals_acc = {}\n",
    "\n",
    "for i, bucket in enumerate(distance_buckets):\n",
    "\n",
    "    print(f\"Training on bucket {i}\")\n",
    "    print(f\"Bucket range: {bucket[0]}–{bucket[1]} tokens\")\n",
    "    # Get first bucket\n",
    "    bucket = bucketed[distance_buckets[i]]\n",
    "    examples = len(bucket)\n",
    "\n",
    "    max_len = distance_buckets[i][1]\n",
    "\n",
    "    cfg = TrainConfig(\n",
    "        emb_dim=256,\n",
    "        hidden_dim=256,\n",
    "        bidirectional=True,\n",
    "        max_len=max_len,\n",
    "        epochs=15,\n",
    "        alpha=0.95,\n",
    "        batch_size=512,\n",
    "        lr=0.0007,\n",
    "        seed=42,\n",
    "    )\n",
    "    set_seed(cfg.seed)\n",
    "    random.shuffle(bucket)\n",
    "    print(\"=\"*100)\n",
    "    print(f\"Training on bucket {i} FOFENet\")\n",
    "    print(\"=\"*100)\n",
    "    start_time = time.time()\n",
    "    val_acc_fofe = train_one_bucket(bucket, max_len, vocab, cfg)\n",
    "    end_time = time.time()\n",
    "    print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "    # Save accuracy\n",
    "    vals_acc[(\"fofe\", max_len)] = val_acc_fofe\n",
    "\n",
    "    print(\"=\"*100)\n",
    "    print(f\"Training on bucket {i} BiLSTM\")\n",
    "    print(\"=\"*100)\n",
    "    start_time = time.time()\n",
    "    val_acc_lstm = train_one_bucket_lstm(bucket, max_len, vocab, cfg)\n",
    "    end_time = time.time()\n",
    "    print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "    # Save accuracy\n",
    "    vals_acc[(\"lstm\", max_len)] = val_acc_lstm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
